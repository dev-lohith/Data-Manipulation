{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d2c8f95f",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import glob"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5dee4245-6a0f-46f2-957a-eef2b1691048",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Set the path to the directory where your CSV files are located\n",
    "csv_directory = \"./Data/CSV/\"\n",
    "\n",
    "# Get a list of all CSV files in the directory\n",
    "csv_files = glob.glob(csv_directory + \"*.csv\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5f6e0f16",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Merge csvs with no column headrs and in order\n",
    "# Create an empty list to store the individual DataFrames\n",
    "dataframes = []\n",
    "\n",
    "# Define the column names\n",
    "column_names = [\n",
    "    \"Postcode\",\n",
    "    \"Positional_quality_indicator\",\n",
    "    \"Eastings\",\n",
    "    \"Northings\",\n",
    "    \"Country_code\",\n",
    "    \"NHS_regional_HA_code\",\n",
    "    \"NHS_HA_code\",\n",
    "    \"Admin_county_code\",\n",
    "    \"Admin_district_code\",\n",
    "    \"Admin_ward_code\"\n",
    "]\n",
    "\n",
    "# Read each CSV file and append its DataFrame to the list\n",
    "for csv_file in csv_files:\n",
    "    df = pd.read_csv(csv_file, names=column_names)\n",
    "    dataframes.append(df)\n",
    "\n",
    "# Merge all DataFrames into a single DataFrame\n",
    "merged_df = pd.concat(dataframes, ignore_index=True)\n",
    "\n",
    "# Print the merged DataFrame\n",
    "print(merged_df)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b3b40dbe-3432-4a85-90b3-8c49062c4e5b",
   "metadata": {},
   "outputs": [],
   "source": [
    "# First csv headers as intial reference for columnn names\n",
    "# Ensure the CSV files list is not empty\n",
    "if csv_files:\n",
    "    # Use the first CSV file in the list as the reference\n",
    "    first_csv_file = csv_files[0]\n",
    "\n",
    "    # Read the first CSV to detect columns\n",
    "    reference_columns = pd.read_csv(first_csv_file).columns.tolist()\n",
    "\n",
    "    # Read and merge other CSVs, ensuring the same columns order\n",
    "    dataframes = []\n",
    "    for csv_file in csv_files:\n",
    "        df = pd.read_csv(csv_file)\n",
    "        df = df.reindex(columns=reference_columns, fill_value=None)\n",
    "        dataframes.append(df)\n",
    "\n",
    "    merged_df = pd.concat(dataframes, ignore_index=True)\n",
    "    print(merged_df)\n",
    "else:\n",
    "    print(\"No CSV files found in the directory.\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e9525e9c-319d-4203-82eb-984815d964b3",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Handling if Columns in each file are not in order:\n",
    "# Create an empty list to store the individual DataFrames\n",
    "dataframes = []\n",
    "\n",
    "# Find common columns among all CSV files\n",
    "common_columns = None\n",
    "for csv_file in csv_files:\n",
    "    df = pd.read_csv(csv_file)\n",
    "    if common_columns is None:\n",
    "        common_columns = df.columns\n",
    "    else:\n",
    "        common_columns = common_columns.intersection(df.columns)\n",
    "\n",
    "# Read each CSV file, filter columns, and append DataFrame\n",
    "for csv_file in csv_files:\n",
    "    df = pd.read_csv(csv_file)\n",
    "    df = df[common_columns]  # Filter columns to include only common columns\n",
    "    dataframes.append(df)\n",
    "\n",
    "# Merge all DataFrames into a single DataFrame\n",
    "merged_df = pd.concat(dataframes, ignore_index=True)\n",
    "\n",
    "# Print the merged DataFrame\n",
    "print(merged_df)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "801a23dd-ac35-4e33-9059-2cac028a7fc6",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Handling Extra and Missing Columns:\n",
    "# Create an empty list to store the individual DataFrames\n",
    "dataframes = []\n",
    "\n",
    "# Dictionary to store columns for each CSV file\n",
    "csv_columns = {}\n",
    "\n",
    "# Find common columns among all CSV files\n",
    "common_columns = None\n",
    "for csv_file in csv_files:\n",
    "    df = pd.read_csv(csv_file)\n",
    "    csv_columns[csv_file] = set(df.columns)  # Store columns for each CSV\n",
    "    if common_columns is None:\n",
    "        common_columns = df.columns\n",
    "    else:\n",
    "        common_columns = common_columns.intersection(df.columns)\n",
    "\n",
    "# Read each CSV file, filter columns, and append DataFrame\n",
    "for csv_file in csv_files:\n",
    "    df = pd.read_csv(csv_file)\n",
    "    missing_columns = list(common_columns - csv_columns[csv_file])\n",
    "    extra_columns = list(csv_columns[csv_file] - common_columns)\n",
    "    print(f\"CSV File: {csv_file}\")\n",
    "    print(f\"Missing Columns: {missing_columns}\")\n",
    "    print(f\"Extra Columns: {extra_columns}\")\n",
    "\n",
    "    df = df[common_columns]  # Filter columns to include only common columns\n",
    "    dataframes.append(df)\n",
    "\n",
    "# Merge all DataFrames into a single DataFrame\n",
    "merged_df = pd.concat(dataframes, ignore_index=True)\n",
    "\n",
    "# Print the merged DataFrame\n",
    "print(merged_df)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a71275b1-611d-4180-b4cd-0568b84dcf07",
   "metadata": {},
   "source": [
    "# JSON Merge"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1b1d8408-45aa-4c30-850e-c25cc881cf81",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import glob, os, json\n",
    "\n",
    "\n",
    "json_dir = '/home/lohitd@nextbillion.ai/Downloads/sorted-melbourne-pizza/sorted/6-false_positive'\n",
    "\n",
    "json_pattern = os.path.join(json_dir, '*.json')\n",
    "file_list = glob.glob(json_pattern)\n",
    "\n",
    "dfs = []\n",
    "for file in file_list:\n",
    "    with open(file) as f:\n",
    "        json_data = pd.json_normalize(json.loads(f.read()))\n",
    "    dfs.append(json_data)\n",
    "df = pd.concat(dfs)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2df1624d-5659-4990-ac75-87e96d24fd0a",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
